{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNBLab Jupyter Notebook Tutorial\n",
    "\n",
    "## SRU-Abfragen erklärt - Tutorial für Einsteiger, die es wissen wollen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dieses Tutorial erklärt die Möglichkeiten, mit Hilfe von Jupyter Notebooks und Python die SRU-Schnittstelle der DNB abzufragen und mit den erhaltenen Antworten zu arbeiten. Das Tutorial erklärt dazu den Aufbau der Abfragen anhand von Beispielen und stützt sich auf die Dokumentation der SRU-Schnittstelle unter https://www.dnb.de/sru.\n",
    "\n",
    "Das Tutorial ist dazu in folgendermaßen aufgebaut: \n",
    "\n",
    "* [1. Einrichten der Arbeitsumgebung](#Teil1) \n",
    "* [2. Abfragen verschiedener Datensätze der DNB](#Teil2)  \n",
    "* [3. Aufbau einer gezielten Suche](#Teil3) \n",
    "* [4. Verarbeiten der Ergebnisse](#Teil4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Einrichten der Arbeitsumgebung  <a class=\"anchor\" id=\"Teil1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um die Arbeitsumgebung für die folgenden Schritte passend einzurichten, importiren wird zunächst die benötigten Python-Biblitoheken: Wir laden dazu \"requests\" für die Abfragen an die SRU-Schnittstelle, ElementTree (als ET) und BeautifulSoup, um unser MARC21-XML analysieren zu können, unicodedata zur Codierung sowie Pandas (als pd) zur Datenmanipulation und -analyse.: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import lxml.etree as ET\n",
    "from bs4 import BeautifulSoup as soup\n",
    "import unicodedata\n",
    "\n",
    "#URL der SRU-Schnittstelle der DNB: \n",
    "base_url = \"https://services.dnb.de/sru\"\n",
    "\n",
    "#Anfrage - wir speichern das Ergebnis in die Variable \"basic_request\":\n",
    "basic_request = requests.get(base_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Antwort der Schnittstelle können wir uns auf verschiedenen Wegen ansehen: So können wir uns bspw. den übergebenen Inhalt als Text ausgeben lassen. Dies ist vor allem dann sinnvoll, wenn wir noch nicht wissen, welches Format die Schnittstelle per default ausliefert. Wenn wir dies bereits wissen, zuvor abgefragt haben oder bereits in unserer Abfrage spezifiert haben (dazu später mehr), können wir uns den Inhalt auch direkt in das passende Format konvertieren lassen. In diesem Fall gibt die SRU-Schnittstelle zunächst HTML zurück:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      "<body>\n",
      "<h1>SRU is running.</h1>\n",
      "Version: 2.29, Build: 2021-02-24T12:42:52 UTC\n",
      "</body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Ausgabe der ursprünglichen Abfrage als Text: \n",
    "print(basic_request.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Abfragen verschiedener Datensätze der DNB  <a class=\"anchor\" id=\"Teil2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir können nun unterschiedliche Bereiche der DNB-Daten abfragen, indem wir die oben definierte Base-URL erweitern. Mölgich sind über die SRU-Schnittstelle Abfragen drei verschiedener Bereiche: \n",
    "\n",
    "* Katalog der Deutschen Nationalbibliothek (DNB) - hierin befinden sich die Titeldaten\n",
    "* Katalog des Deutschen Musikarchivs (DMA)\n",
    "* Katalog der Gemeinsamen Normdatei (GND)\n",
    "\n",
    "Die erweiterungen für die URL sind dabei folgende: \n",
    "\n",
    "* DNB: https://services.dnb.de/sru/dnb\n",
    "* DMA: https://services.dnb.de/sru/dnb.dma\n",
    "* GND: https://services.dnb.de/sru/authorities\n",
    "\n",
    "Werden die jeweiligen Bereiche ohne weitere Spezifikationen abgefragt, senden sie eine \"Explain-Response\" in XML zurück. Mit Hilfe der Programmbibliothek BeautifulSoup \"parsen\" wir die Antwort in XML, d.h. wir wandeln diese Antwort in XML um, und lassen uns diese anzeigen. Achtung: Um die Antwort nicht zu lang werden zu lassen, werden hier nur die ersten 500 Zeichen der Antwort ausgegeben - die eigentliche Antwort ist länger und kann durch einfaches Löschen der Einschränkung \"[0:500]\" in der \"print\"-Zeile komplett angezeigt werden. Natürlich können auch andere Bereiche zur Anzeige gewählt werden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
      "<html>\n",
      " <body>\n",
      "  <explainresponse xmlns=\"http://www.loc.gov/zing/srw/\">\n",
      "   <version>\n",
      "    1.1\n",
      "   </version>\n",
      "   <record>\n",
      "    <recordschema>\n",
      "     http://explain.z3950.org/dtd/2.0/\n",
      "    </recordschema>\n",
      "    <recordpacking>\n",
      "     xml\n",
      "    </recordpacking>\n",
      "    <recorddata>\n",
      "     <ns:explain id=\"Deutsche Nationalbibliothek\" xmlns:ns=\"http://explain.z3950.org/dtd/2.0/\">\n",
      "      <ns:serverinfo protocol=\"sru\" version=\"1.1\">\n",
      "       <ns:host>\n",
      "        services.dnb.de\n",
      "       </\n"
     ]
    }
   ],
   "source": [
    "dnb = requests.get(\"https://services.dnb.de/sru/dnb\")\n",
    "\n",
    "response = soup(dnb.content)\n",
    "print(response.prettify()[0:500])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wenn wir nun eine Suchanfrage im DNB-Katalog vornehmen wollen, definieren wir zunächst über die Wahl der URL unseren Suchbereich. Mit Hilfe der Variable \"parameter\" übergeben wir dann all die Werte, die wir für unsere Suchanfrage per SRU brauchen. \n",
    "\n",
    "Besonders relevant sind im Folgenden dabei die beiden Punkte 'query' : 'Klimawandel', sowie 'recordSchema' : 'MARC21-xml'. Statt \"Klimawandel\" kann hier jeder beliebige Suchbegriff eingetragen werden - auch Suchbegriffe, die aus mehreren Wörtern bestehen, können hier mittels boolscher Operatoren übergeben werden. Wie genau solche Anfragen formuliert werden müssen, kann unter https://www.dnb.de/sru nachgelesen werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
      "<html>\n",
      " <body>\n",
      "  <searchretrieveresponse xmlns=\"http://www.loc.gov/zing/srw/\">\n",
      "   <version>\n",
      "    1.1\n",
      "   </version>\n",
      "   <numberofrecords>\n",
      "    6018\n",
      "   </numberofrecords>\n",
      "   <records>\n",
      "    <record>\n",
      "     <recordschema>\n",
      "      MARC21-xml\n",
      "     </recordschema>\n",
      "     <recordpacking>\n",
      "      xml\n",
      "     </recordpacking>\n",
      "     <recorddata>\n",
      "      <record type=\"Bibliographic\" xmlns=\"http://www.loc.gov/MARC21/slim\">\n",
      "       <leader>\n",
      "        00000nam a22000008c 4500\n",
      "       </leader>\n",
      "       <controlfield tag=\"001\">\n",
      "        1147699615\n",
      "       </controlfield>\n",
      "       <controlfield tag=\"003\">\n",
      "        DE-101\n",
      "       </controlfield>\n",
      "       <controlfield tag=\"005\">\n",
      "        20201001130612.0\n",
      "       </controlfield>\n",
      "       <controlfield tag=\"007\">\n",
      "        tu\n",
      "       </controlfield>\n",
      "       <controlfield tag=\"008\">\n",
      "        171204s2025    gw ||||| |||| 00||||ger\n",
      "       </controlfield>\n",
      "       <datafield ind1=\" \" ind2=\" \" tag=\"015\">\n",
      "        <subfield code=\"a\">\n",
      "         17,N50\n",
      "        </subfie\n"
     ]
    }
   ],
   "source": [
    "dnb_url = \"https://services.dnb.de/sru/dnb\"\n",
    "\n",
    "#Parameter, die wir mit einer Anfrage übergeben wollen: \n",
    "parameter = {'version' : '1.1' , 'operation' : 'searchRetrieve' , 'query' : 'Klimawandel', 'recordSchema' : 'MARC21-xml'} \n",
    "\n",
    "r1 = requests.get(dnb_url, params = parameter)\n",
    "\n",
    "#print(r.url)\n",
    "\n",
    "response = soup(r1.content)\n",
    "print(response.prettify()[0:1000])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zu beachten ist, dass die Suche nach einem Stichwort über den 'query'-Befehl eine allgemeine Suche über alle Titeldaten darstellt. Die Suche ist allerdings nicht auf Titel oder ähnliches beschränkt, sondern durchsucht die Datensätze im Gesamten. Auch nach beispielsweise Autor\\*innennamen kann auf diese Art gesucht werden, jedoch muss bedacht werden, dass auch Titel, die den gesuchten Namen enthalten, in diesem Fall als Treffer ausgegeben werden. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Aufbau einer gezielten Suche  <a class=\"anchor\" id=\"Teil3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um die Suche direkt auf bestimmte Angaben wie bspw. Titel oder Autor\\*in einzugrenzen, können unter anderem folgende Befehle genutzt werden:\n",
    "\n",
    " - tit= Suche im Titeleintrag\n",
    " - atr= Suche nach Verfasser\\*in (Person oder Organisation)\n",
    " - per= Suche nach Personen (in allen relevanten Feldern)\n",
    " - sw = Suche nach Schlagworten\n",
    " - jhr = Suche nach Erscheinungszeitraum \n",
    " - ...\n",
    "\n",
    "Eine detaillierte Übersicht über die verschiedenen Abfragemöglichkeiten gibt es hier: https://www.dnb.de/expertensuche. Dabei können die unterschiedlichen Parameter auch beliebig in der Suchanfrage kombiniert werden - zu beachten ist hier lediglich, dass diese immer Teil der \"Query\" sind. \n",
    "\n",
    "Für die Ausgabe der Ergebnisse können wir außerdem zwischen drei Formaten wählen, indem wir den entsprechenden Code hinter 'recordSchema' ändern:  \n",
    "\n",
    " - MARC21-xml (XML-Variante von MARC 21)\n",
    " - oai_dc (DNB Casual - Auswahl von Dublin-Core-Elementen - nur für Titeldaten!)\n",
    " - RDFxml (RDF - Linked Data Service)\n",
    "\n",
    "Eine Suchanfrage nach Titeln, die das Suchwort \"Klimawandel\" enthalten und im Jahr 2005 erschienen sind und die im Format DNB Casual ausgegeben werden soll, sieht dann folgendermaßen aus: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
      "<html>\n",
      " <body>\n",
      "  <searchretrieveresponse xmlns=\"http://www.loc.gov/zing/srw/\">\n",
      "   <version>\n",
      "    1.1\n",
      "   </version>\n",
      "   <numberofrecords>\n",
      "    27\n",
      "   </numberofrecords>\n",
      "   <records>\n",
      "    <record>\n",
      "     <recordschema>\n",
      "      oai_dc\n",
      "     </recordschema>\n",
      "     <recordpacking>\n",
      "      xml\n",
      "     </recordpacking>\n",
      "     <recorddata>\n",
      "      <dc xmlns=\"http://www.openarchives.org/OAI/2.0/oai_dc/\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:dnb=\"http://d-nb.de/standards/dnbterms\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\">\n",
      "       <dc:title>\n",
      "        Anpassung an den Klimawandel : Gründe, Folgen, Handlungsoptionen / Bundesministerium für Wirtschaftliche Zusammenarbeit und Entwicklung ; Gtz, Deutsche Gesellschaft für Technische Zusammenarbeit (GTZ) GmbH\n",
      "       </dc:title>\n",
      "       <dc:creator>\n",
      "        Deutschland / Bundesministerium für Wirtschaftliche Zusammenarbeit und Entwicklung\n",
      "       </dc:creator>\n",
      "       <dc:publisher>\n",
      "        Eschborn : GTZ\n",
      "       </dc\n"
     ]
    }
   ],
   "source": [
    "#Parameter, die wir mit einer Anfrage übergeben wollen: \n",
    "parameter = {'version' : '1.1' , 'operation' : 'searchRetrieve' , 'query' : 'tit=Klimawandel and jhr=2005',\n",
    "             'recordSchema' : 'oai_dc', 'maximumRecords': '100'} \n",
    "\n",
    "r = requests.get(dnb_url, params = parameter)\n",
    "\n",
    "#Parsen der Antwort \"r\" als XML in die neue Variable \"response\":\n",
    "response = soup(r.content)\n",
    "\n",
    "#Schöne Ausgabe der ersten 1000 Zeichen: \n",
    "print(response.prettify()[0:1000])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Zeile 8 der Antwort entdecken wir folgenden XML-Block, der uns die Gesamtzahl der gefundenen Ergebnisse verrät:  \n",
    "```\n",
    "<numberofrecords>\n",
    "    27\n",
    "</numberofrecords>\n",
    "```\n",
    "\n",
    "Wenn wir nicht unbedingt im XML nach diesem Schnipsel suchen wollen, können wir auch unseren Code damit beauftragen, den entsprechenden Abschnitt mithilfe des Zusatzes \".find('numberofrecords')\" zu suchen. Der Zusatz \".find('suchtext')\" sucht dabei nach dem ersten Element, welches den Suchtext in Klammern enthält, was für unseren Fall der Gesamtergebnisse ausreichend ist. Wenn dagegen mehrere XML-Tags mit demselben Namen gesucht und ausgegeben werden sollen, nutzt man \".find_all('suchtext')\". \n",
    "\n",
    "Im Anschluss lassen wir uns den Inhalt zwischen den beiden \"numberofrecords\"-Tags ausgeben, indem wir an unsere Variable das Attribut \".text\" anhängen. Zum Vergleich kann die gesamte Variable \"number\" (unten auskommentiert) ausgegeben werden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27 Ergebnisse\n"
     ]
    }
   ],
   "source": [
    "number = response.find('numberofrecords')\n",
    "print(number.text, 'Ergebnisse')\n",
    "#print(number)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da die einzelnen Treffer bzw. Werke jeweils durch \"record\"-Tags gekennzeichnet sind, suchen wir nun nach diesen und speichern sie in der Variable \"records\" zwischen. Zum Vergleich lassen wir uns im Anschluss noch die Länge der Variable ausgeben und sehen, dass diese mit der Angabe unter \"numberofrecords\" übereinstimmt. \n",
    "\n",
    "ACHTUNG: Dies funkioniert nur bis zu einer Treffermenge von insgesamt 100! Auch bei größeren Treffermengen wird im folgenden maximal die Länge 100 angezeigt - wie wir damit umgehen, folgt weiter unten. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27 Ergebnisse\n"
     ]
    }
   ],
   "source": [
    "records = response.find_all('record')\n",
    "print(len(records), 'Ergebnisse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Ergebnisse werden als Liste gespeichert, was bedeutet, dass unsere Variable \"records\" eine Listenvariable ist. Die Ergebnisse stehen dabei jeweils an einem eigenen Listenplatz - bei 9 Ergebnissen gibt es in unserer Liste also 9 Einträge. Da der erste Eintrag allerdings an Listenplatz 0 steht, sind die Plätze von 0-8 mit den 9 Einträgen belegt - dies ist wichtig, wenn wir einzelene Listenplätze adressieren wollen. \n",
    "\n",
    "Wir können uns so bspw. den 3. Einträg anzeigen lassen, in dem wir uns den Platz mit der Nummer 2 aufrufen: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<record><recordschema>oai_dc</recordschema><recordpacking>xml</recordpacking><recorddata><dc xmlns=\"http://www.openarchives.org/OAI/2.0/oai_dc/\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:dnb=\"http://d-nb.de/standards/dnbterms\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\">\n",
      "<dc:title>Informationssystem KLARA 1.0 : Klimawandel - Auswirkungen, Risiken, Anpassung ; Analysen spezifischer Verwundbarkeiten und Handlungsoptionen im Land Baden-Württemberg / LfU, Landesanstalt für Umweltschutz Baden-Württemberg ...  Projektleiter: Manfred Stock ...</dc:title>\n",
      "<dc:creator>Stock, Manfred [Mitwirkender]</dc:creator>\n",
      "<dc:publisher>Karlsruhe : LfU</dc:publisher>\n",
      "<dc:date>2005</dc:date>\n",
      "<dc:identifier xsi:type=\"dnb:IDN\">97609228X</dc:identifier>\n",
      "<dc:subject>330 Wirtschaft</dc:subject>\n",
      "<dc:subject>360 Soziale Probleme, Sozialdienste, Versicherungen</dc:subject>\n",
      "<dc:subject>550 Geowissenschaften</dc:subject>\n",
      "<dc:format>1 CD-ROM</dc:format>\n",
      "</dc></recorddata><recordposition>6</recordposition></record>\n"
     ]
    }
   ],
   "source": [
    "print(records[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um das Ganze nun etwas bequemer nutzen zu können, führen wir die verschiedenen einzelnen Schritte nun in einer Funktion zusammen, die wir dann nur noch mit unserer Wunschabfrage aufrufen müssen, um unsere Ergebnisse zu erhalten: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sru_dnb(query): \n",
    "\n",
    "    dnb_url = \"https://services.dnb.de/sru/dnb\"\n",
    "    parameter = {'version' : '1.1' , 'operation' : 'searchRetrieve' , 'query' : query,\n",
    "                 'recordSchema' : 'oai_dc', 'maximumRecords': '100'} \n",
    "\n",
    "    r = requests.get(dnb_url, params = parameter)\n",
    "    response = soup(r.content)\n",
    "    records = response.find_all('record')  \n",
    "    \n",
    "    return records\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27 Ergebnisse\n"
     ]
    }
   ],
   "source": [
    "myquery = sru_dnb('tit=Klimawandel and jhr=2005')\n",
    "print(len(myquery), \"Ergebnisse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da wir allerdings im Vorfeld meist nicht wissen, wieviele Ergebnisse unsere Suchanfrage erzeugen wird und wir damit rechnen, dass häufig Ergebnismengen von über 100 Treffern vorkommen, passen wir die Funktion nun noch etwas an. Dazu bauen wir eine kleine Schleife, die zunächst abfragt, wieviele Treffer gefunden wurden und dann entscheidet: Werden bis zu 100 Treffer gemeldet gibt es keinen Änderungsbedarf und die Funktion kann so einfach durchlaufen. Werden jedoch mehr als 100 Treffer gefunden, wird die Anfrage in 100er Schritte aufgeteilt und die Ergebnisse jeweils zwischengespeichert. Sobald alle Teile der Anfrage verarbeitet wurden, wird dann das gesammelte Ergebnis übergeben. Die Funktion sieht dann folgendermaßen aus: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sru_dnb(query): \n",
    "\n",
    "    dnb_url = \"https://services.dnb.de/sru/dnb\"\n",
    "    parameter = {'version' : '1.1' , 'operation' : 'searchRetrieve' , 'query' : query,\n",
    "                 'recordSchema' : 'oai_dc', 'maximumRecords': '100'} \n",
    "\n",
    "    r = requests.get(dnb_url, params = parameter)\n",
    "    response = soup(r.content)\n",
    "    records = response.find_all('record')  \n",
    "    \n",
    "    \n",
    "    if len(records) < 100:\n",
    "        return records\n",
    "    \n",
    "    else: \n",
    "        num_results = 100\n",
    "        i = 101\n",
    "        \n",
    "        while num_results == 100:\n",
    "            \n",
    "            parameter.update({'startRecord': i})\n",
    "            r = requests.get(dnb_url, params=parameter)\n",
    "            xml = soup(r.content)\n",
    "            new_records = xml.find_all('record')\n",
    "            records+=new_records\n",
    "            i+=100\n",
    "            num_results = len(new_records)\n",
    "            \n",
    "        return records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diese Funktion wird auch bereits im Tutorial [\"Wie können Daten mittels der SRU-Schnittstelle abgerufen werden?\"](https://www.dnb.de/DE/Professionell/Services/WissenschaftundForschung/DNBLab/dnblab_node.html#doc731014bodyText4) verwendet. \n",
    "\n",
    "Eine Abfrage für das Titelstichwort \"Klimawandel\", kombiniert nun mit den Jahr 2019, ergibt nun 272 Ergebnisse: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "273 Ergebnisse\n"
     ]
    }
   ],
   "source": [
    "myquery = sru_dnb('tit=Klimawandel and jhr=2019')\n",
    "print(len(myquery), \"Ergebnisse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Verarbeiten der Ergebnisse  <a class=\"anchor\" id=\"Teil4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um mit diesen Ergebnissen nun weiterarbeiten zu können, überführen wir diese aus dem XML in eine tabellarische Form. \n",
    "\n",
    "Auch hier arbeiten wir wieder mit einer Funktion, um diese für verschiedene Anfragen nachnutzen zu können. Wir nennen diese Funktion \"parse_record\", weil wir ihr beim späteren Aufruf die einzelnen Records, die wir durch unsere Anfrage an die SRU-Schnittstelle übergeben werden. Die Funktion soll dann nach einem bestimmten Feld suchen (bspw. Creator, Titel etc.) und uns den Inhalt dieses Feldes zurückgeben. \n",
    "\n",
    "Hierfür geben wir den Namespace unseres XML an - dieser ist in der XML-Antwort der Schnittstelle zu finden. Außerdem parsen wir unsere Antwort mit Hilfe der Bibliothek ElementTree (hier kurz ET) in die passende Form zur Weiterverarbeitung. Danach definieren wir, wo der Titel zu finden ist (im Feld beginnend mit \"dc:title\") und holen uns von dort den Inhalt (den Titeltext). Wenn die Funktion dort nichts findet, gibt sie das des Titeltextes den Text \"unknown\" zurück:   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_record(record):\n",
    "    \n",
    "    ns = {\"dc\": \"http://purl.org/dc/elements/1.1/\"}\n",
    "    xml = ET.fromstring(unicodedata.normalize(\"NFC\", str(record)))\n",
    "    \n",
    "    \n",
    "    #titel\n",
    "    titel = xml.xpath('.//dc:title', namespaces=ns)\n",
    "    try:\n",
    "        titel = titel[0].text\n",
    "    except:\n",
    "        titel = \"unkown\"\n",
    "        \n",
    "        \n",
    "    meta_dict = {\"titel\":titel}\n",
    "    \n",
    "    return meta_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im Anschluss führen wir nun die Funktion aus, in dem wir ihr die einzelnen records aus unserer Antwort \"myquery\" übergeben. Das Ergebnis (\"output\") überführen wir dann in ein Dataframe (\"df\") und lassen uns dieses anzeigen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>titel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12. Mitteldeutscher Rinder-Workshop in Bernbur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25. Welt-Klimakonferenz in Madrid, deutschland...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>55 knackige Punkte, wie wir gemeinsam den Klim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>55 knackige Punkte, wie wir gemeinsam den Klim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adaptive potential of the Arctic diatom Thalas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>Der Klimawandel wird weitergehen — eine unbequ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>Fortbildungsangebote zu Klimawandel, Hitze und...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>Globalisierung, Klimawandel, Migration / von red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>Nachfrageprognose und Wasserverbrauchssteuerun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>Zunehmende Wetterextreme sind Gründe, die gesu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>273 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 titel\n",
       "0    12. Mitteldeutscher Rinder-Workshop in Bernbur...\n",
       "1    25. Welt-Klimakonferenz in Madrid, deutschland...\n",
       "2    55 knackige Punkte, wie wir gemeinsam den Klim...\n",
       "3    55 knackige Punkte, wie wir gemeinsam den Klim...\n",
       "4    Adaptive potential of the Arctic diatom Thalas...\n",
       "..                                                 ...\n",
       "268  Der Klimawandel wird weitergehen — eine unbequ...\n",
       "269  Fortbildungsangebote zu Klimawandel, Hitze und...\n",
       "270   Globalisierung, Klimawandel, Migration / von red\n",
       "271  Nachfrageprognose und Wasserverbrauchssteuerun...\n",
       "272  Zunehmende Wetterextreme sind Gründe, die gesu...\n",
       "\n",
       "[273 rows x 1 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = [parse_record(record) for record in myquery]\n",
    "df = pd.DataFrame(output)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dieses können wir uns nun als CSV-Datei oder auch direkt im Excel-Format xlsx ausgeben lassen: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Titelabfrage.csv\", index=False) \n",
    "#df.to_excel(\"Titelabfrage.xlsx\", encoding='utf8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da wir allerdings nicht nur den Titel in unsere Tabelle bzw. Dataframe überführen wollen, sondern weitere Angaben wie IDN, Creator, Sachschlagworte, Publikationsdatum etc. erweitern wir die Funktion entsprechend. Das Prinzip bleibt dabei gleich. Da es jedoch Felder in Dublin Core gibt, die sich wiederholen können, wurde im Folgenden der Code für die Schlagworte (subject) so angepasst, dass für jeden Titel bis zu drei Schlagworte aus den Daten extrahiert werden können:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_record(record):\n",
    "    \n",
    "    ns = {\"dc\": \"http://purl.org/dc/elements/1.1/\", \n",
    "          \"xsi\": \"http://www.w3.org/2001/XMLSchema-instance\"}\n",
    "    xml = ET.fromstring(unicodedata.normalize(\"NFC\", str(record)))\n",
    "    \n",
    "    #idn\n",
    "    idn = xml.xpath(\".//dc:identifier[@xsi:type='dnb:IDN']\", namespaces=ns) \n",
    "    if idn: \n",
    "        idn = idn[0].text\n",
    "    else:\n",
    "        idn = 'fail'\n",
    "    \n",
    "    \n",
    "    #titel\n",
    "    titel = xml.xpath('.//dc:title', namespaces=ns)\n",
    "    try:\n",
    "        titel = titel[0].text\n",
    "    except:\n",
    "        titel = \"unkown\"\n",
    "        \n",
    "    \n",
    "    #creator\n",
    "    creator = xml.xpath('.//dc:creator', namespaces=ns)\n",
    "    try:\n",
    "        creator = creator[0].text\n",
    "    except:\n",
    "        creator = \"unkown\"\n",
    "        \n",
    "    \n",
    "    #date\n",
    "    date = xml.xpath('.//dc:date', namespaces=ns)\n",
    "    try:\n",
    "        date = date[0].text\n",
    "    except:\n",
    "        date = \"unkown\"\n",
    "        \n",
    "        \n",
    "        \n",
    "    #subjects: \n",
    "    subject = xml.xpath(\".//dc:subject\", namespaces=ns) \n",
    "    \n",
    "    if len(subject) == 1: \n",
    "        subject1 = subject[0].text\n",
    "        subject2 = 'N/A'\n",
    "        subject3 = 'N/A'\n",
    "    elif len(subject) == 2:\n",
    "        subject1 = subject[0].text\n",
    "        subject2 = subject[1].text\n",
    "        subject3 = 'N/A'\n",
    "    elif len(subject) == 3:\n",
    "        subject1 = subject[0].text\n",
    "        subject2 = subject[1].text\n",
    "        subject3 = subject[2].text\n",
    "    else:\n",
    "        subject1 = 'N/A'\n",
    "        subject2 = 'N/A'\n",
    "        subject3 = 'N/A'\n",
    "        \n",
    "        \n",
    "    #weitere IDs: \n",
    "    urn = xml.xpath(\".//dc:identifier[@xsi:type='tel:URN']\", namespaces=ns) \n",
    "    if urn: \n",
    "        urn = urn[0].text\n",
    "    else:\n",
    "        urn = 'N/A'\n",
    "        \n",
    "        \n",
    "    meta_dict = {\"idn\":idn, \"titel\":titel, \"creator\":creator, \"date\":date, \n",
    "                 \"subject1\":subject1, \"subject2\":subject2, \"subject3\":subject3, \"urn\":urn}\n",
    "    \n",
    "    return meta_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idn</th>\n",
       "      <th>titel</th>\n",
       "      <th>creator</th>\n",
       "      <th>date</th>\n",
       "      <th>subject1</th>\n",
       "      <th>subject2</th>\n",
       "      <th>subject3</th>\n",
       "      <th>urn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1206546913</td>\n",
       "      <td>12. Mitteldeutscher Rinder-Workshop in Bernbur...</td>\n",
       "      <td>Scholz, Heiko [Herausgeber]</td>\n",
       "      <td>2019</td>\n",
       "      <td>630 Landwirtschaft, Veterinärmedizin</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1206340592</td>\n",
       "      <td>25. Welt-Klimakonferenz in Madrid, deutschland...</td>\n",
       "      <td>unkown</td>\n",
       "      <td>2019</td>\n",
       "      <td>ERROR</td>\n",
       "      <td>ERROR</td>\n",
       "      <td>ERROR</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1176214233</td>\n",
       "      <td>55 knackige Punkte, wie wir gemeinsam den Klim...</td>\n",
       "      <td>Matthée, Jörg</td>\n",
       "      <td>2019</td>\n",
       "      <td>300 Sozialwissenschaften, Soziologie, Anthropo...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>117864622X</td>\n",
       "      <td>55 knackige Punkte, wie wir gemeinsam den Klim...</td>\n",
       "      <td>Matthée, Jörg [Verfasser]</td>\n",
       "      <td>2019</td>\n",
       "      <td>330 Wirtschaft</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>urn:nbn:de:101:1-2019022020104008152243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1186248742</td>\n",
       "      <td>Adaptive potential of the Arctic diatom Thalas...</td>\n",
       "      <td>Wolf, Klara Katharina Estrella [Verfasser]</td>\n",
       "      <td>2019</td>\n",
       "      <td>570 Biowissenschaften, Biologie</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>urn:nbn:de:gbv:46-00107155-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>1212955544</td>\n",
       "      <td>Der Klimawandel wird weitergehen — eine unbequ...</td>\n",
       "      <td>Neubäumer, Renate [Verfasser]</td>\n",
       "      <td>2019</td>\n",
       "      <td>330 Wirtschaft</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>urn:nbn:de:101:1-2020070112021412765574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>118985712X</td>\n",
       "      <td>Fortbildungsangebote zu Klimawandel, Hitze und...</td>\n",
       "      <td>Schoierer, Julia [Verfasser]</td>\n",
       "      <td>2019</td>\n",
       "      <td>610 Medizin, Gesundheit</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>urn:nbn:de:101:1-2019070412392166110088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>1184762767</td>\n",
       "      <td>Globalisierung, Klimawandel, Migration / von red</td>\n",
       "      <td>red [Verfasser]</td>\n",
       "      <td>2019</td>\n",
       "      <td>610 Medizin, Gesundheit</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>urn:nbn:de:101:1-2019042819000522717073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>1177804212</td>\n",
       "      <td>Nachfrageprognose und Wasserverbrauchssteuerun...</td>\n",
       "      <td>Yildiz, Özgür [Verfasser]</td>\n",
       "      <td>2019</td>\n",
       "      <td>330 Wirtschaft</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>urn:nbn:de:101:1-2019021204072972329687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>1189857065</td>\n",
       "      <td>Zunehmende Wetterextreme sind Gründe, die gesu...</td>\n",
       "      <td>Mücke, Hans-Guido [Verfasser]</td>\n",
       "      <td>2019</td>\n",
       "      <td>610 Medizin, Gesundheit</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>urn:nbn:de:101:1-2019070412385518284037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>273 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            idn                                              titel  \\\n",
       "0    1206546913  12. Mitteldeutscher Rinder-Workshop in Bernbur...   \n",
       "1    1206340592  25. Welt-Klimakonferenz in Madrid, deutschland...   \n",
       "2    1176214233  55 knackige Punkte, wie wir gemeinsam den Klim...   \n",
       "3    117864622X  55 knackige Punkte, wie wir gemeinsam den Klim...   \n",
       "4    1186248742  Adaptive potential of the Arctic diatom Thalas...   \n",
       "..          ...                                                ...   \n",
       "268  1212955544  Der Klimawandel wird weitergehen — eine unbequ...   \n",
       "269  118985712X  Fortbildungsangebote zu Klimawandel, Hitze und...   \n",
       "270  1184762767   Globalisierung, Klimawandel, Migration / von red   \n",
       "271  1177804212  Nachfrageprognose und Wasserverbrauchssteuerun...   \n",
       "272  1189857065  Zunehmende Wetterextreme sind Gründe, die gesu...   \n",
       "\n",
       "                                        creator  date  \\\n",
       "0                   Scholz, Heiko [Herausgeber]  2019   \n",
       "1                                        unkown  2019   \n",
       "2                                 Matthée, Jörg  2019   \n",
       "3                     Matthée, Jörg [Verfasser]  2019   \n",
       "4    Wolf, Klara Katharina Estrella [Verfasser]  2019   \n",
       "..                                          ...   ...   \n",
       "268               Neubäumer, Renate [Verfasser]  2019   \n",
       "269                Schoierer, Julia [Verfasser]  2019   \n",
       "270                             red [Verfasser]  2019   \n",
       "271                   Yildiz, Özgür [Verfasser]  2019   \n",
       "272               Mücke, Hans-Guido [Verfasser]  2019   \n",
       "\n",
       "                                              subject1 subject2 subject3  \\\n",
       "0                 630 Landwirtschaft, Veterinärmedizin      N/A      N/A   \n",
       "1                                                ERROR    ERROR    ERROR   \n",
       "2    300 Sozialwissenschaften, Soziologie, Anthropo...      N/A      N/A   \n",
       "3                                       330 Wirtschaft      N/A      N/A   \n",
       "4                      570 Biowissenschaften, Biologie      N/A      N/A   \n",
       "..                                                 ...      ...      ...   \n",
       "268                                     330 Wirtschaft      N/A      N/A   \n",
       "269                            610 Medizin, Gesundheit      N/A      N/A   \n",
       "270                            610 Medizin, Gesundheit      N/A      N/A   \n",
       "271                                     330 Wirtschaft      N/A      N/A   \n",
       "272                            610 Medizin, Gesundheit      N/A      N/A   \n",
       "\n",
       "                                         urn  \n",
       "0                                        N/A  \n",
       "1                                        N/A  \n",
       "2                                        N/A  \n",
       "3    urn:nbn:de:101:1-2019022020104008152243  \n",
       "4              urn:nbn:de:gbv:46-00107155-14  \n",
       "..                                       ...  \n",
       "268  urn:nbn:de:101:1-2020070112021412765574  \n",
       "269  urn:nbn:de:101:1-2019070412392166110088  \n",
       "270  urn:nbn:de:101:1-2019042819000522717073  \n",
       "271  urn:nbn:de:101:1-2019021204072972329687  \n",
       "272  urn:nbn:de:101:1-2019070412385518284037  \n",
       "\n",
       "[273 rows x 8 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = [parse_record(record) for record in myquery]\n",
    "df = pd.DataFrame(output)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Damit ist unsere Abfrage deutlich erweitert und wir können sie wieder als CSV exportieren oder auch direkt in Python mit dem Dataframe weiterarbeiten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Titelabfrage_erweitert.csv\", index=False, encoding='utf8') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"Titelabfrage_erweitert.xlsx\", index=False, encoding='utf8') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
